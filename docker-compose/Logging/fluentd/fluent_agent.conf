#collect data
<source>
  @type tail
  @id input_tail_containers
  path /logs/docker_logs/*/*-json.log
  pos_file /data/docker.pos
  read_from_head true
  tag docker.**
  skip_refresh_on_startup false
  refresh_interval 10s
  enable_watch_timer true
  enable_stat_watcher false
  <parse>
    @type "json"
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

# Do not collect fluentd's own logs to avoid infinite loops.
<label @FLUENT_LOG>
  <match fluent.**>
    @type null
  </match>
</label>

# add field with hostname
<filter docker.logs.**>
  @type record_transformer
  enable_ruby
  <record>
    hostname "#{Socket.gethostname}"
  </record>
</filter>

<match docker.logs.**>
  @type rewrite_tag_filter
  <rule>
   key $['attrs']['service_name']
   pattern "^#{ENV['env']}_.+$"
   tag "docker.#{ENV['env']}"
  </rule>
</match>

<match "docker.#{ENV['env']}">
  @type forward
  @id forward_docker
  <server>
    name main_server
    host 172.29.27.62
    port 24224
  </server>
  <buffer>
    @type file
    path /data/buffers
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 2s
    retry_forever
    retry_max_interval 30
    chunk_limit_size 4M
    queue_limit_length 512
    overflow_action block
  </buffer>
</match>
