<source>
  @type tail
  @id input_tail_containers
  path /logs/docker_logs/*/*-json.log
  pos_file /data/docker.pos
  read_from_head true
  tag "docker.**"
  skip_refresh_on_startup false
  refresh_interval 10s
  enable_watch_timer true
  enable_stat_watcher false
  <parse>
    @type "json"
    time_format %Y-%m-%dT%H:%M:%S.%NZ
    localtime
  </parse>
</source>

<label @FLUENT_LOG>
  <match fluent.**>
    @type null
  </match>
</label>

# change tag to need tag with rule on pattern (servise_name like all)
<match docker.logs.**>
  @type rewrite_tag_filter
  <rule>
   key $['attrs']['service_name']
   pattern ^(.*)
   tag "docker.#{ENV['env']}"
  </rule>
</match>

<filter "docker.#{ENV['env']}">
  @type record_transformer
  enable_ruby
  <record>
    hostname "#{Socket.gethostname}"
 </record>
</filter>

<filter "docker.#{ENV['env']}">
  @type parser
  format json
  key_name log
 reserve_data true
</filter>

<filter "docker.#{ENV['env']}">
  @type concat
  key log
  stream_identity_key container_id
  multiline_start_regexp /^-e:2:in `\/'/
  multiline_end_regexp /^-e:4:in/
</filter>

<match "docker.#{ENV['env']}">
  @type forward
  @id forward_docker
  <server>
    name main_server
    host "#{ENV['collector_ip']}" 
    port 24224
  </server>
  <buffer>
    @type file
    path /data/buffers
    flush_mode interval
    retry_type exponential_backoff
    flush_thread_count 2
    flush_interval 2s
    retry_forever
    retry_max_interval 30
    chunk_limit_size 4M
    queue_limit_length 512
    overflow_action block
  </buffer>
</match>